{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'sdss.csv'\n",
    "raw_data = []\n",
    "with open(filename) as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        #print(row.split(','))\n",
    "        raw_data.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = []\n",
    "y_label = []\n",
    "for row in raw_data[1:]:\n",
    "    y_label.append(row[13])   # Append label\n",
    "    x_data.append(list(map(float, (row[0:13] + row[14:])))) # Convert to list of float\n",
    "x_data = np.array(x_data)\n",
    "print(len(x_data))\n",
    "print(len(y_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_encoding = preprocessing.LabelBinarizer()\n",
    "lb_encoding.fit(y_label)\n",
    "y_data = lb_encoding.transform(y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_encoding.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lb_encoding.inverse_transform(np.array([[1, 0, 0], [0, 1, 0], [0, 0, 1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for useless data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_list = [np.std(x_data[:,i]) for i in range(x_data.shape[1])]\n",
    "\n",
    "for i,std in enumerate(std_list):\n",
    "    if std == 0:\n",
    "        print(\"Useless feature in index \",i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Here we found two features that are exactly the same for all samples. Therefore, they are useless and are going to be removed. Their indices are 0 and 9 </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_features = [i for i in range(x_data.shape[1]) if i not in [0,9]]\n",
    "x_data = x_data[:,valid_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Subtracting by mean and dividing by standand deviation\n",
    "def normalize_data(x_data):\n",
    "    for i in range(x_data.shape[1]):\n",
    "        x_data[:, i] = x_data[:, i] - np.mean(x_data[:, i])\n",
    "        x_data[:, i] = x_data[:, i]/np.std(x_data[:, i])\n",
    "    return x_data\n",
    "\n",
    "x_data = normalize_data(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(x_data.shape[1]):\n",
    "    print(np.mean(x_data[:,i]), np.std(x_data[:,i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split  in Train, Validation and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shuffle data \n",
    "def shuffle_lists_the_same_way(x_data, y_data):\n",
    "    assert len(x_data) == len(y_data)\n",
    "    p = np.random.permutation(len(x_data))\n",
    "    return np.array(x_data)[p], np.array(y_data)[p]\n",
    "\n",
    "x_data, y_data = shuffle_lists_the_same_way(x_data, y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Separating 60% train, 20% validation and 20% test\n",
    "train_percentage = 0.6\n",
    "validation_percentage = 0.2\n",
    "test_percentage = 0.2\n",
    "\n",
    "def separare_train_validation_test(x_data, y_data, train_percentage=0.6, validation_percentage=0.2, test_percentage=0.2):\n",
    "    total = len(x_data)\n",
    "    train_slice = int(train_percentage*total)\n",
    "    validation_slice = train_slice + int(validation_percentage*total)\n",
    "    test_slice = validation_slice + int(test_percentage*total)\n",
    "    \n",
    "    x_train, y_train = x_data[:train_slice], y_data[:train_slice]\n",
    "    x_validation, y_validation = x_data[train_slice:validation_slice], y_data[train_slice:validation_slice]\n",
    "    x_test, y_test = x_data[validation_slice:test_slice], y_data[validation_slice:test_slice]\n",
    "    return x_train, y_train, x_validation, y_validation, x_test, y_test\n",
    "\n",
    "x_train, y_train, x_validation, y_validation, x_test, y_test = separare_train_validation_test(x_data, y_data, train_percentage, validation_percentage, test_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape, y_train.shape)\n",
    "print(x_validation.shape, y_validation.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Data were split randomly, checking with number of samples for each class are somewhat distributed </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(y_train, axis=0))\n",
    "print(np.sum(y_validation, axis=0))\n",
    "print(np.sum(y_test, axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=([15])))\n",
    "model.add(Dense(128, activation='relu', input_shape=([15])))\n",
    "model.add(Dense(3, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.fit(x_train, y_train, \n",
    "          batch_size=1, epochs=20, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_validation, y_validation, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
